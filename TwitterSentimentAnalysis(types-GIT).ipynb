{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder ='C:XXpathtothefolderXX/'\n",
    "file='datadocs.csv'\n",
    "#file2='datadocs2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(folder+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makesure dataframe has no duplicates and time-columns are datetime format\n",
    "dfa=dfa.drop_duplicates(subset=['tweet_id'])\n",
    "dfa.tweet_created_at = pd.to_datetime(dfa['tweet_created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate retweets\n",
    "dfNORT=dfa[~dfa.text.str.contains(\"RT @\")]\n",
    "#and check the difference\n",
    "print(\"total of tweets = \"+str(len(dfa))+\" Without RT= \"+ str(len(dfNORT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfNORT.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of tweets in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN=['en']\n",
    "dfNORTtextcleanEN=dfNORT[dfNORT['lang'].isin(EN)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis with Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNORTtextcleanEN['sentiment'] = dfNORTtextcleanEN['text'].apply(lambda tweet: TextBlob(tweet).sentiment)\n",
    "#df['language'] = df['text'].apply(lambda tweet: TextBlob(tweet).detect_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNORTtextcleanENsentiment_series =dfNORTtextcleanEN['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['polarity', 'subjectivity']\n",
    "dfsent = pd.DataFrame(dfNORTtextcleanENsentiment_series, columns=columns, index=dfNORTtextcleanEN.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNORTtextcleanENSENT=pd.concat([dfNORTtextcleanEN, dfsent], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNORTtextcleanENSENT.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "data = dfNORTtextcleanENSENT['polarity']\n",
    "figsize=(20,10)\n",
    "#N, bins, patches = ax.hist(data, bins=100, edgecolor='white', linewidth=1)\n",
    "ax.set_ylabel(\"Number of tweets\", fontsize=14)\n",
    "ax.set_xlabel(\"Polarity of tweets (negative <----> positive)\", fontsize=14)\n",
    "ax.set_title('Tweet Polarity visualisation',fontsize=18)\n",
    "N, bins, bars = ax.hist(data, bins=100, color=\"skyblue\", edgecolor='white', linewidth=1)\n",
    "for bar in bars:\n",
    "    if bar.get_x() < 0:\n",
    "        bar.set_facecolor(\"lightcoral\")\n",
    "plt.savefig(folder+'polarity'+file+'.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "data = dfNORTtextcleanENSENT['subjectivity']\n",
    "figsize=(20,10)\n",
    "ax.set_ylabel(\"Number of tweets\", fontsize=14)\n",
    "ax.set_xlabel(\"Subjectivity of tweets (factual <----> subjective)\", fontsize=14)\n",
    "ax.set_title('Tweet Subjectivity visualisation',fontsize=18)\n",
    "N, bins, bars = ax.hist(data, bins=100, color=\"grey\", edgecolor='white',  density=True, linewidth=1)\n",
    "bin_centers = 0.5*(bins[:-1]+bins[1:])\n",
    "cm = plt.cm.get_cmap(\"copper\")\n",
    "col = bin_centers - max(bin_centers)\n",
    "col /= min(col)\n",
    "\n",
    "for c, p in zip(col, bars):\n",
    "    plt.setp(p, \"facecolor\", cm(c))\n",
    "\n",
    "#for useful colors check this:\n",
    "#https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "\n",
    "plt.savefig(folder+'Subjectivity'+file+'.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More about Vader (can do with multiple languages)\n",
    "#https://python.plainenglish.io/twitter-sentiment-analysis-using-vader-tweepy-b2a62fba151e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function obtained here: https://python.plainenglish.io/twitter-sentiment-analysis-using-vader-tweepy-b2a62fba151e\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNORTtextcleanEN['Newtext'] = clean_tweets(dfNORTtextcleanEN['text'])\n",
    "dfNORTtextcleanEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REF for this: https://github.com/sidneykung/twitter_hate_speech_detection/blob/master/preprocessing/VADER_sentiment.ipynb\n",
    "# function to calculate polarity scores\n",
    "pol = lambda x: analyzer.polarity_scores(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfNORTtextcleanEN\n",
    "clean_df=dfNORTtextcleanEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column 'polarity' in clean_df\n",
    "clean_df['polarity'] = clean_df['Newtext'].apply(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that worked\n",
    "clean_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polaritydf=clean_df['polarity'].apply(pd.Series)\n",
    "polaritydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([clean_df, polaritydf], axis=1 )\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "data = df['compound']\n",
    "figsize=(20,10)\n",
    "#N, bins, patches = ax.hist(data, bins=100, edgecolor='white', linewidth=1)\n",
    "ax.set_ylabel(\"Number of tweets\", fontsize=14)\n",
    "ax.set_xlabel(\"Compound of tweets (negative <----> positive)\", fontsize=14)\n",
    "ax.set_title('Tweet (VADER) Compound visualisation',fontsize=18)\n",
    "N, bins, bars = ax.hist(data, bins=100, color=\"skyblue\", edgecolor='white', linewidth=1)\n",
    "for bar in bars:\n",
    "    if bar.get_x() < 0:\n",
    "        bar.set_facecolor(\"lightcoral\")\n",
    "plt.savefig(folder+'VADERCompound'+file+'.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110707b9d723e1c444c54a483b1f1584fb109b164cd3977d8615832db624a1d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
